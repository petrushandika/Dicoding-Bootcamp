# Pengenalan AI

AI atau kecerdasan buatan adalah ilmu tentang mengajarkan mesin untuk belajar, bertindak, dan berpikir seperti manusia untuk melakukan tugas-tugas dalam kehidupan nyata.

AI dibuat untuk membantu memecahkan masalah kognitif yang umumnya terkait dengan kecerdasan manusia, seperti pembelajaran, pemecahan masalah, dan pengenalan pola.

#### Sejarah Singkat

AI pertama kali dikembangkan pada tahun 1950 oleh John McCarthy, Marvin Minsky, dan para ilmuwan lainnya di Massachusetts Institute of Tehcnology (MIT) yang membentuk kelompok penelitian untuk mempelajari AI.

Lalu, pada tahun 1956 dibuatlah sebuah konferensi AI Darthmouth Summer Research Project on Artificial Intelligence (DSRPAI) yang menjadi tonggak awal perkembangan AI sebagai bidang ilmu yang mandiri. Pada konferensi ini, para ilmuwan sepakat untuk memusatkan perhatian mereka pada pembangunan program-program komputer yang mampu "belajar" dan "berpikir" seperti manusia.

## Taksonomi AI

#### Artificial Intelligence (AI)

AI adalah teknologi yang menerapkan peniruan perilaku manusia terhadap komputer supaya dapat mempelajari dan melakukan tugas tanpa perlu bantuan eksplisit tentang output yang diharapkan. Mudahnya AI memungkinkan untuk belajar pengalaman, mengidentifikasi pola, membuat keputusan, dan menyelesaikan tugas kompleks dengan cepat dan efisien.

#### Machine Learning (ML)

Machine learning adalah sebuah teknologi yang menggunakan metode statistika untuk membuat komputer dapat mempelajari pola pada data tanpa perlu diprogram secara eksplisit.

ML bergantung pada algoritma yang digunakan untuk menganalisis data dalam jumlah yang besar, belajar dari pengetahuan berdasarkan data, dan memberikan keputusan berdasarkan pengalaman yang dipelajarinya dengan tepat.

#### Deep Learning

Deep Learning merupakan pembelajaran mesin yang didasari oleh jaringan saraf tiruan, proses yang lebih kompleks dari pada Machine Learning karena pada tahapan ini proses pembelajarannya terdiri dari beberapa bagian mulai dari input, hidden layer, dan output.

Jaringan saraf tiruan menerima masukan berupa bilangan numerik kemudian memproses masukan tersebut untuk menghasilkan sebuah keluaran. Pada sebuah jaringan saraf tiruan, semakin banyak jumlah hidden layer dalam sistem, semakin lama jaringan saraf tersebut memproduksi hasil, tetapi juga semakin kompleks masalah yang dapat diselesaikan.

#### Generative AI

Generative AI merupakan bagian lebih dalam dari Deep Learning. Pembelajaran Generative AI dapat menghasilkan berbagai konten baru berdasarkan input yang diberikan oleh pengguna.

Model Generative AI dapat menghasilkan berbagai konten mulai dari bahasa, kode, suara, hingga gambar. Salah satu contoh implementasi Generative AI adalah DALL-E. DALL-E sendiri merupakan Generative AI yang dapat menciptakan gambar dari deskriptif tekstual.

## AI Workflow

#### Digitalise & Collect

Digitalise & collect merupakan tahapan pengumpulan dan penyimpanan data yang akan digunakan pada proses pembangunan AI.

#### Transform

Transform adalah proses perubahan yang dimana data yang telah dikumpulkan akan diproses secara berulang mulai dari persiapan data, mengubah data menjadi format yang dibutuhkan, hingga mengevaluasi data dengan mengidentifikasi data yang tidak dibutuhkan.

#### Train

Tahap Train menentukan algoritma yang cocok untuk pengembangan AI ini. Proses pelatihan/train ini bertujuan untuk membuat komputer dapat mempelajari data yang diberikan sehingga komputer dapat melakukan tugas berdasarkan data yang telah ia pelajari.

#### Execute

Model AI yang telah dilatih dan disempurnakan dapat digunakan untuk melakukan hal yang bisa manusia lakukan. Selama fase ini, keakuratan model juga dievaluasi secara terus-menerus. Proses eksekusi dianalisis ulang untuk memastikan bahwa sistem memenuhi harapan dan memberikan umpan balik untuk perbaikan.

#### Provide Insights to Make Decisions

Ketika sudah siap kita harus melakukan ekstraksi dari pengetahuan yang diberikan oleh model tersebut. Proses ini membantu pengambilan keputusan serta meningkatkan pemahaman kita dalam pengembangan AI selanjutnya.

## Pengenalan Data

### Apa Itu Data

Data adalah informasi, terutama fakta atau angka, dikumpulkan untuk diperiksa dan dipertimbangkan, serta digunakan untuk membantu pengambilan keputusan atau informasi dalam bentuk elektronik yang dapat disimpan dan digunakan oleh komputer.

### Data, Dataset, dan Basis Data

Data adalah fakta, nyata, dan informasi yang tersimpan di dalamnya dapat berbentuk teks, angka, gambar, suara, dan banyak bentuk lainnya. Data dalam konteks dataset dan basis data mengacu pada kumpulan informasi yang relevan serta dikumpulkan, disimpan, dan dikelola untuk tujuan tertentu. Dengan kata lain, data merupakan entri tunggal atau informasi individual.

Dataset adalah kumpulan data yang disusun secara terstruktur. Biasanya, dataset dipresentasikan dalam bentuk tabel alias kumpulan baris dan kolom yang dapat disimpan pada beberapa format, seperti CSV, Excel, JSON, dan format lainnya.

Basis data merupakan kumpulan data yang diatur dan disimpan secara terorganisir sehingga dapat diambil dan diakses dengan mudah. Selain itu, ia juga dapat menyimpan berbagai macam tipe data, termasuk teks, nomor, gambar, dan tipe data lainnya.

### Tipe-Tipe Data

#### Data Terstruktur

Data terstruktur merupakan jenis data yang memiliki format dan tata letak yang tetap atau teratur. Artinya, data ini diatur dalam suatu pola atau struktur yang konsisten sehingga mudah dibaca, diproses, dan dianalisis oleh komputer atau manusia. Jenis data terstruktur umumnya memiliki definisi yang jelas seperti kolom dalam tabel atau bidang dalam dokumen teks. Data ini memiliki 2 turunan, yaitu data kuantitatif dan data kategorikal.

#### Data Kuantitatif

Data kuantitatif adalah jenis data yang dapat diukur atau diungkapkan dalam bentuk angka. Data ini digunakan untuk mengukur atau menggambarkan jumlah, besaran, atau atribut-atribut yang dapat diukur secara numerik.

- Data Kontinu

  Data kontinu dapat direpresentasikan dalam berbagai nilai numerik, seperti bilangan desimal, bulat, dan lain-lain. Beberapa contoh tipe data kontinu yang umum adalah tinggi, berat, waktu, suhu, usia, dan lain-lain.

- Data Diskrit

  Data diskrit merupakan data numerik yang hanya bisa direpresentasikan dengan bilangan bulat dan tidak dapat dibagi ke dalam unit yang lebih kecil.

#### Data Kategorikal

Data kategorikal mengacu pada bentuk informasi yang dapat disimpan dan diidentifikasi berdasarkan nama atau labelnya. Data kategorikal merupakan data yang dapat dikelompokkan dan terbagi berdasarkan karakteristik atau ciri khasnya masing-masing.

- Data Ordinal

  Data ordinal adalah jenis pengelompokan data yang memiliki urutan atau harus disusun secara berurutan dengan mekanisme peringkat.

- Data Nominal

  Data nominal adalah jenis pengelompokan data yang tidak memiliki keterkaitan dengan data lainnya dan tidak memiliki arti khusus.

#### Data Tidak Terstruktur

Data tidak terstruktur adalah jenis data yang tidak memiliki format atau struktur yang jelas. Data ini cenderung bervariasi bentuknya dan sulit untuk diorganisasi dalam kategori atau kolom tertentu. Data tidak terstruktur seringkali memiliki sifat lebih bebas, tidak terbatas, dan lebih kompleks dibandingkan dengan data terstruktur.

## Kriteria Data untuk AI

#### Garbage in, Garbage out (GIGO)

Garbage in, garbage out dalam bahasa Indonesia memiliki arti sampah masuk, sampah keluar. Arti dari sampah ini merupakan keluaran dari sistem AI yang kita bangun sangat bergantung pada data masukan yang diterima. Jika kita memiliki data masukan yang buruk, besar kemungkinan AI yang dihasilkan tidak sesuai harapan.

#### Masalah dalam Data

Permasalahan yang terjadi pada data biasanya disebabkan oleh kesalahan ketika pengumpulan atau pencatatan data. Data yang diperoleh dengan cara yang salah atau bahkan diambil dari sumber yang tidak dapat dipercaya juga bisa disebut sebagai data sampah.

Permasalahan umum yang sering terjadi terdapat pada kualitas data, seperti data yang tidak relevan (incorrect), data berbeda dengan yang lain (outlier), data duplikat, data kosong, data yang tidak benar, dan masih banyak lagi.

Dari beberapa permasalahan di atas, setidaknya kita akan sering menemui data kosong. Kita dapat menanganinya dengan beberapa cara, seperti menghapus data yang kosong tersebut atau mengisi data kosong dengan nilai rata-rata atau median jika datanya berupa numerik.

#### Infrastruktur Data di Industri

Data infrastruktur mengacu kepada hardware, software, dan teknologi jaringan yang digunakan untuk mendukung proses pengelolaan data.

Tujuan dari infrastruktur data adalah untuk menyediakan pengelolaan data yang baik, memproses data, dan menganalisis data yang ada.

Tujuan Infrastruktur :

- Manajemen Data

  Dengan menggunakan infrastruktur data yang baik, maka tempat penyimpanan data akan terpusat. Hal ini akan membuat data dalam sebuah organisasi menjadi lebih aman dan mudah untuk dikelola.

- Pemrosesan Data

  Infrastruktur data menyediakan daya komputasi dan sumber daya yang dibutuhkan untuk memproses dan menganalisis data dengan jumlah besar. Hal ini memungkinkan organisasi untuk melakukan analisis dan membuat pemodelan yang kompleks sehingga dapat membantu mendapatkan informasi dan keputusan yang tepat berdasarkan data.

- Integrasi Data

  Menggunakan infrastruktur data yang baik, kita dapat mengintegrasikan data dari berbagai sumber.

- Keamanan Data

  Infrastruktur data menyediakan fitur dan protokol keamanan untuk melindungi data sensitif dari akses yang tidak sah, pencurian, atau penyalahgunaan.

## Pengenalan Machine Learning

Machine learning menggunakan algoritma untuk menganalisis data dalam jumlah yang besar, belajar dari pengetahuan yang ada pada data, dan akhirnya memberikan keputusan berdasarkan pengalaman yang dimilikinya.

### Traditional Programming vs Machine Learning

Machine learning adalah suatu cabang ilmu yang memberi komputer kemampuan untuk belajar tanpa diprogram secara eksplisit.

Pemrograman tradisional memiliki keterbatasan karena ia rigid dengan sekumpulan aturan “if” dan “else” untuk memproses data atau menyesuaikan dengan masukan.

### Tipe-Tipe Machine Learning

#### Supervised Learning

Supervised learning adalah kategori machine learning yang dalam proses pembelajarannya menggunakan data yang memiliki label atau jawaban. Model machine learning, model akan melakukan perhitungan komputasi terhadap input yang diberikan berdasarkan algoritma yang digunakan.

#### Unsupervised Learning

Unsupervised learning, data yang digunakan pada proses pembelajarannya tidak memiliki jawaban atau label. Unsupervised learning akan melakukan proses interpretasi, yaitu menemukan sebuah pola berdasarkan karakteristik dataset yang ada. Tahapan ini dibantu oleh algoritma yang dapat melakukan perhitungan komputasi untuk membantu menemukan pola atau struktur yang ada di dalamnya.

#### Reinforcement Learning

Reinforcement learning adalah teknik yang mempelajari bagaimana membuat keputusan terbaik secara berurutan untuk memaksimalkan ukuran sukses kehidupan nyata. Entitas pembuat keputusan atau yang biasa disebut agent belajar melalui proses trial dan error.

### Machine Learning Workflow

Machine learning workflow memiliki tahapan iteratif yang berarti prosesnya bisa berulang sesuai dengan kebutuhan. Anda dapat mengevaluasi ulang proses yang Anda jalankan dan kembali ke langkah sebelumnya ketika dibutuhkan. Machine learning worfklow umumnya memiliki lima tahapan yang berkesinambungan.

#### Pengumpulan Data

Machine Learning Engineer bertugas untuk membangun model ML, tentu proses pengumpulan datanya tidak semudah mengunduh dataset yang sudah jadi. Anda perlu mengumpulkan dan mengekstrak sendiri data dari berbagai sumber, seperti dari database, file, data sensor, dan sumber lainnya.

Anda juga perlu berurusan dengan berbagai jenis tipe data mulai dari structured data (seperti berkas excel atau basis data SQL), hingga unstructured data (seperti berkas text, email, video, audio, gambar, data sensor, dan lainnya). Seorang analis yang bekerja pada sebuah perusahaan yang melakukan riset dan penasehatan global menyatakan bahwa lebih dari 80% data yang digunakan saat ini adalah unstructured data.

#### Data Preprocessing

Data preprocessing adalah tahapan pengolahan data lebih lanjut sehingga menjadi lebih siap dalam pengembangan model machine learning. Proses ini mengubah fitur-fitur data ke dalam bentuk yang mudah diinterpretasikan dan diproses oleh algoritma machine learning. seperti data cleaning, data transformation, dan data integration.

Beberapa hal yang bisa dilakukan dalam proses data cleaning antara lain

- Penanganan missing value,
- Data yang tidak konsisten,
- Duplikasi data,
- Ketidakseimbangan data,
- Dan lain sebagainya.

Selain itu, ada juga beberapa hal yang bisa dilakukan untuk proses data transformation seperti

- Scaling atau mengubah skala data agar sesuai dengan skala tertentu. Adapun metode umum yang digunakan ada dua, yaitu:

  - Standarisasi, mengubah data agar memiliki mean = 0 dan standar deviasi = 1. Biasanya digunakan jika data memiliki distribusi normal.
  - Normalisasi, mengubah data dalam rentang tertentu, biasanya [0,1] atau [-1,1], agar semua fitur memiliki skala yang sama. Cocok untuk data dengan skala yang berbeda atau tidak terdistribusi normal.

- Mengonversi data menjadi format yang seharusnya, sebagai contoh:
  - Kolom tanggal memiliki format object, kita tukar menjadi format datetime.
  - Kolom dengan isi data kategorikal tetapi formatnya numeric, kita ganti nilai uniknya menjadi nilai kategorikal dan konversi menjadi Object.

Lalu, bagaimana dengan data integration? Berikut beberapa hal yang bisa dilakukan pada tahap data integration.

- Menggabungkan dataset.
- Menghilangkan fitur yang duplikat.
- Menyamakan format.
- Dan lain sebagainya.

#### Model Development

Pilihan model atau metode yang tidak tepat dapat menyebabkan kesimpulan yang menyesatkan atau performa prediksi yang mengecewakan. Sebagai contoh, saat memiliki kasus klasifikasi biner, kita perlu mempertimbangkan model terbaik untuk data kita, apakah logistic regression atau SVM classifier.

Setelah kita menentukan metode yang cocok untuk data yang ada, kita perlu mengubah hyperparameter untuk mendapatkan performa terbaik dari model. Hyperparameter di sini merupakan variabel yang digunakan untuk mengontrol proses pelatihan model, contohnya seperti epochs, optimizer, dan lain sebagainya.

Mengubah nilai hyperparameter saat kita menjalankan algoritma ML akan memberikan hasil atau performa model yang berbeda. Proses menemukan performa terbaik model dengan pengaturan hyperparameter yang berbeda ini juga disebut model development.

#### Model Evaluation

Proses model evaluation adalah menilai kinerja model ML pada data baru, yaitu data yang belum pernah “dilihat” oleh model sebelumnya. Bertujuan untuk membuat estimasi generalisasi error dari model yang dipilih, yaitu seberapa baik kinerja model tersebut pada data baru.

Langkah evaluasi model dapat dijabarkan sebagai berikut.

- Memprediksi label pada data uji.
- Menghitung jumlah dari hasil prediksi berdasarkan data uji. Pada tahap ini, kita menghitung keseluruhan kondisi yang ada, seperti jumlah dari kondisi prediksi yang memiliki status benar ataupun salah.
- Membandingkan hasil prediksi dengan data label yang kita miliki. Dari data perbandingan ini, kita dapat menghitung akurasi atau performa model.

#### Model Deployment

Setelah model dievaluasi, model siap untuk dipakai pada tahap produksi yang biasanya disebut model deployment. Caranya adalah dengan menyimpan model yang telah dilatih dari tahap preprocessing hingga pipeline prediksi. Selanjutnya, jangan lupa untuk membawa seluruh tahapan pada data preprocessing untuk digunakan pada tahapan prediksi. Simpan seluruh tahapan yang dilakukan pada data preprocessing pada sebuah fungsi bernama predict yang berguna untuk memproses data baru. Kemudian, deploy model tersebut ke sebuah platform seperti web, mobile, IoT, dan lain sebagainya. Last but not least, kita dapat membuat prediksi dengan memanggil fungsi predict() yang sebelumnya telah dibuat.

### Model Maintanance

#### Manual Retraining

Teknik pertama adalah melakukan proses pelatihan ulang pada model dari awal sehingga data-data baru yang ditemui di tahap produksi akan digabung dengan data lama. Selanjutnya, model dilatih ulang dari awal menggunakan data lama dan data baru.

#### Continous Learning

Teknik kedua untuk menjaga model kita up-to-date adalah continuous learning yang menggunakan sistem terotomasi dalam pelatihan ulang model. Berikut alur dari continuous learning.

- Menyimpan data-data baru yang ditemui pada tahap produksi. Contohnya, ketika sistem mendapatkan harga emas naik, data harga tersebut akan disimpan di database.
- Ketika data-data baru yang dikumpulkan cukup, lakukan pengujian akurasi dari model terhadap data baru.
- Jika akurasi model menurun seiring waktu, gunakan data baru atau kombinasi data lama dan baru untuk melatih dan men-deploy ulang model.

## Pengenalan Deep Learning

Deep learning adalah bagian dari bidang keilmuan AI yang mengajarkan komputer untuk memproses data yang terinspirasi dari cara kerja otak manusia. Model deep learning dapat mengerjakan tugas yang lebih kompleks dari machine learning. Dengan kompleksitas yang cukup tinggi, model deep learning dapat mengenali gambar, teks, suara, dan data lainnya.

### Mengenal Artificial Neural Network (ANN)

Artificial Neural Network (ANN) atau Jaringan Saraf Tiruan adalah sebuah model machine learning yang terinspirasi dari neuron/saraf yang terdapat pada otak manusia.

#### Cara Kerja Saraf Manusia

Sebuah saraf terdiri dari 3 (tiga) bagian utama, yaitu akson, dendrit, dan badan sel yang di dalamnya terdapat nukleus.

- Nukleus berisi materi genetik dan bertugas mengontrol seluruh aktivitas sel.
- Akson adalah cabang yang terlihat seperti ekor yang panjang. Ia bertugas untuk mengirimkan pesan dari sel. Panjang akson berkisar antara beberapa kali lebih panjang dari badan sel, bahkan hingga 10 ribu kali lebih panjang dari badan sel.
- Dendrit adalah cabang-cabang pendek yang terlihat seperti cabang pohon yang tugasnya menerima pesan untuk sel.

#### Cara Kerja Jaringan Saraf Tiruan

Artificial neural network atau jaringan saraf tiruan memiliki komponen dasar bernama perceptron. Frank Rosenblatt dari Cornell Aeronautical Library adalah ilmuwan yang pertama kali menemukan perceptron pada tahun 1957 [8]. Perceptron pada jaringan saraf tiruan terinspirasi dari neuron pada jaringan saraf di otak manusia. Pada jaringan saraf tiruan, perceptron dan neuron merujuk pada hal yang sama.

Sebuah perceptron menerima masukan berupa bilangan numerik. Perceptron kemudian memproses masukan tersebut untuk menghasilkan sebuah keluaran.

#### Computer Vision

Computer vision merupakan bidang yang memungkinkan komputer atau sistem memperoleh informasi dari gambar digital, video, dan input visual lainnya.

#### Natural Language Processing

Natural Language Processing atau NLP merupakan subbidang dari Artificial Intelligence (AI) untuk memproses, menganalisis, memahami, dan menghasilkan bahasa manusia. NLP termasuk bidang keilmuan AI karena pemrosesan bahasa dianggap sebagai bagian dari kecerdasan manusia. Penggunaan bahasa merupakan keterampilan paling menonjol yang membedakan manusia dengan makhluk lainnya.

NLP menghasilkan beberapa informasi sebagai output seperti label, representasi semantik, dan sebagainya. Teknik NLP digunakan di setiap aplikasi cerdas yang melibatkan bahasa alami. Ia merupakan komponen penting dalam berbagai aplikasi perangkat lunak yang kita gunakan dalam kehidupan sehari-hari.

#### Penerapan Natural Language Processing

Pada bidang marketing, salah satu aplikasi NLP yang telah dibahas di materi sebelumnya adalah analisis sentimen untuk social media monitoring. Selain yang telah disebutkan tadi, NLP memiliki peran signifikan pada berbagai produk dan layanan. Salah satu contoh penerapan yang paling populer pada aplikasi NLP adalah mesin pencari.

Salah satu contohnya adalah pada tahap analisis kueri (query analysis). Analisis kueri mengidentifikasi intensi pengguna saat mengetikkan kata kunci pada mesin pencari, kemudian memberikan informasi yang relevan. Misalnya, jika kita mengetik nama seorang tokoh terkenal pada mesin pencari, akan muncul berbagai informasi penting yang relevan dengan tokoh tersebut. Selain itu, juga muncul beberapa berita mengenai tokoh tersebut.

Selain itu, mesin pencari juga memiliki fungsi koreksi dan rekomendasi kueri. Fungsi ini biasanya muncul saat kita mengetikkan ejaan yang salah dalam mesin pencari. Ketika hal tersebut terjadi, mesin menunjukkan koreksi dengan label seperti “menampilkan hasil untuk (ejaan yang dikoreksi)” atau “telusuri (ejaan salah yang kita ketik)”. Fungsi ini tentu memudahkan proses pencarian dan mengoptimalkan pengalaman pengguna.

### Proses di Balik Deep Learning

```python
import tensorflow as tf

mnist = tf.keras.datasets.fashion_mnist
(x_train, y_train),(x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
model = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(512, activation=tf.nn.relu),
    tf.keras.layers.Dense(10, activation=tf.nn.softmax)
])
model.compile(optimizer=tf.optimizers.Adam(),
              loss=’sparse_categorical_crossentropy’,
              metrics=[‘accuracy’])
model.fit(x_train, y_train, epochs=10)
```

Proses pembelajaran ini terjadi melalui 3 tahapan, yaitu input layer, hidden layer, dan output layer. Berikut definisi dari 3 layer utama pada model sequential.

- Input Layer

  Layer yang memiliki parameter ‘input_shape’. input_shape sendiri adalah resolusi dari gambar-gambar pada data latih. Dalam hal ini, sebuah gambar MNIST memiliki resolusi 28x28 pixel sehingga input shape-nya adalah (28, 28). Sebuah layer Flatten pada Keras akan berfungsi untuk meratakan input. Meratakan di sini artinya mengubah gambar yang merupakan matriks 2 dimensi menjadi array 1 dimensi. Pada kasus kita, sebuah gambar MNIST yang merupakan matriks 28x28 elemen, akan diubah menjadi larik/array satu dimensi sebesar 784 elemen.

- Hidden Layer

  Dense layer pada Keras merupakan layer yang dapat dipakai sebagai hidden layer dan output layer pada sebuah MLP (Multilayer Perceptron). Parameter unit merupakan jumlah perceptron pada sebuah layer. Kita dapat menggunakan fungsi aktivasi relu (rectified linear unit) atau fungsi aktivasi lain untuk hidden layer kita.

- Output Layer

  Output layer didefinisikan dengan membuat sebuah dense layer. Jumlah unit menyesuaikan dengan jumlah label pada dataset. Untuk fungsi aktivasi pada layer output, gunakan fungsi aktivasi sigmoid ketika hanya terdapat 2 kelas/label pada dataset. Untuk dataset yang memiliki 3 kelas atau lebih, gunakan fungsi aktivasi softmax. Fungsi aktivasi softmax akan memilih kelas mana yang memiliki probabilitas tertinggi. Untuk data fashion MNIST, kita akan menggunakan fungsi aktivasi softmax karena terdapat 10 kelas.
